{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"07_3_TF_MNIST_hello_keras.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"W1e5h7-Y6kEM","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","mnist = tf.keras.datasets.mnist"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dQZwiMnL6ueC","colab_type":"code","colab":{}},"source":["(x_train, y_train),(x_test, y_test) = mnist.load_data()\n","x_train = x_train / 255.0\n","x_test = x_test / 255.0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RL6IK1ncaNM9","colab_type":"code","outputId":"c2fb0759-714b-416f-acd3-f110b7c79687","executionInfo":{"status":"ok","timestamp":1559009321955,"user_tz":-540,"elapsed":1386,"user":{"displayName":"김혜주","photoUrl":"","userId":"02435794378876656796"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["x_train.shape   # 공부하는 과정이니 이런거 확인해보기 "],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 28, 28)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"28qGwLa8aR9t","colab_type":"code","outputId":"34337fe0-2f0e-4811-f93b-b4b4ca9b28a0","executionInfo":{"status":"ok","timestamp":1559009321956,"user_tz":-540,"elapsed":1371,"user":{"displayName":"김혜주","photoUrl":"","userId":"02435794378876656796"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["x_test.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 28, 28)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"ANEKq3-w6yaA","colab_type":"code","colab":{}},"source":["#모델 구조 설정\n","model = tf.keras.models.Sequential([\n","  tf.keras.layers.Flatten(input_shape=(28, 28)),\n","  #tf.keras.layers.Dense(512, activation=tf.nn.relu),  # 이걸 활성화시키면 더 정확해짐. 히든 노드를 둠으로써 정확도가 올라간다. 이 위에 3줄이 가장 중요 렐루 의미알기\n","  tf.keras.layers.Dense(256, activation=tf.nn.relu),\n","  tf.keras.layers.Dense(10, activation=tf.nn.softmax)  #소프트맥스는 시그모이드랑 비슷  이 구조 잘봐두기 dense라는 거미줄이 우리가 늘 보던 구조임.\n","])\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KVnsM9ixaehF","colab_type":"code","outputId":"d61def92-68da-473b-cb3f-18f5803b9617","executionInfo":{"status":"ok","timestamp":1559009321962,"user_tz":-540,"elapsed":1350,"user":{"displayName":"김혜주","photoUrl":"","userId":"02435794378876656796"}},"colab":{"base_uri":"https://localhost:8080/","height":251}},"source":["model.summary()   #Dense라는 표현 알아두기 layer의 타입이 dense 나중에 우리 dense없앨거야"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten_1 (Flatten)          (None, 784)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 256)               200960    \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                2570      \n","=================================================================\n","Total params: 203,530\n","Trainable params: 203,530\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PF2t75vdeqUK","colab_type":"code","outputId":"bd7513c4-f4d4-43ae-e967-e6bb929637d5","executionInfo":{"status":"ok","timestamp":1559009321964,"user_tz":-540,"elapsed":1340,"user":{"displayName":"김혜주","photoUrl":"","userId":"02435794378876656796"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["784 * 10 + 10"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7850"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"q2x2OVukebRB","colab_type":"code","outputId":"3cd40b28-5e02-47d1-cd51-0b556353bcd9","executionInfo":{"status":"ok","timestamp":1559009321965,"user_tz":-540,"elapsed":1328,"user":{"displayName":"김혜주","photoUrl":"","userId":"02435794378876656796"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["784*512 + 512"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["401920"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"2QrvfYwJfZrI","colab_type":"code","outputId":"d4192578-062d-4eb6-da35-b0f708a1b418","executionInfo":{"status":"ok","timestamp":1559009321966,"user_tz":-540,"elapsed":1316,"user":{"displayName":"김혜주","photoUrl":"","userId":"02435794378876656796"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["512*10 + 10"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5130"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"KcZ1MMgCfrjp","colab_type":"code","outputId":"628fc366-50c6-412f-bb45-e03c93f1543d","executionInfo":{"status":"ok","timestamp":1559009321967,"user_tz":-540,"elapsed":1309,"user":{"displayName":"김혜주","photoUrl":"","userId":"02435794378876656796"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["401920 + 5130"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["407050"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"RnQgKk4Nbebq","colab_type":"text"},"source":["params 가 왜 7850개 일까? 전체 파라미터도 7850개고 컴퓨터가 학습할 수 있는 파라미터도 7850개네  이게 뭔뜻이지?\n","784 * 10 + 10 인것 같은데 그게 무슨 의미지?"]},{"cell_type":"code","metadata":{"id":"BhohR45lalHz","colab_type":"code","colab":{}},"source":[" # 모델 푸는 방법 지정\n","  model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n1WeEb6Z6wLN","colab_type":"code","outputId":"22404cf1-7b4e-467a-fb08-3d272baf2390","executionInfo":{"status":"ok","timestamp":1559009362977,"user_tz":-540,"elapsed":42290,"user":{"displayName":"김혜주","photoUrl":"","userId":"02435794378876656796"}},"colab":{"base_uri":"https://localhost:8080/","height":215}},"source":["#풀자! \n","model.fit(x_train, y_train, epochs=5)  #epoch를 더 많이 돌리면 좀 더 정확해지겠지 그리고  히든레이어를 두면 더 정확해질거임/ 이건 사람이 정했으니 하이퍼파라미터 5의 의미는 한 epoch당 60000개의 데이터를 한번 다쓰는것. 5니까 그걸 5번돌린다. 여기서의 accuracy는 train데이터의 정확도임. 봤던데이터로 하니까 정확도\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","60000/60000 [==============================] - 8s 138us/sample - loss: 0.2264 - acc: 0.9340\n","Epoch 2/5\n","60000/60000 [==============================] - 8s 134us/sample - loss: 0.0923 - acc: 0.9722\n","Epoch 3/5\n","60000/60000 [==============================] - 8s 134us/sample - loss: 0.0618 - acc: 0.9808\n","Epoch 4/5\n","60000/60000 [==============================] - 8s 136us/sample - loss: 0.0450 - acc: 0.9861\n","Epoch 5/5\n","60000/60000 [==============================] - 8s 135us/sample - loss: 0.0332 - acc: 0.9895\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f70781bbd30>"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"e0FHtyJWI6Tz","colab_type":"text"},"source":["### *Real World Challenge*: Large difference between training and testing set accuracy"]},{"cell_type":"markdown","metadata":{"id":"0sE5Hh97Izji","colab_type":"text"},"source":["test accuracy와 training accuracy의 뜻도 알기 차이를 알아야함. 정확도가 얼마다라고 얘기할때 정확도를 보통 training accuracy로 얘기하는데 의미있는건 test accuracy"]},{"cell_type":"markdown","metadata":{"id":"o3SHmEaDk4II","colab_type":"text"},"source":["#### Test accuracy"]},{"cell_type":"code","metadata":{"id":"H4pBTMpH9kb6","colab_type":"code","outputId":"36ac3bd3-af6f-4f8b-9c54-b23479058f78","executionInfo":{"status":"ok","timestamp":1559009363615,"user_tz":-540,"elapsed":42918,"user":{"displayName":"김혜주","photoUrl":"","userId":"02435794378876656796"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["model.evaluate(x_test, y_test)  # train 에 사용안했던 10000개 데이터 넣고 돌렸더니 정확도가 97%\n","# model.evaluate(x_test[:2], y_test[:2])  # 2개 데이터만 test해보고 싶을때."],"execution_count":0,"outputs":[{"output_type":"stream","text":["10000/10000 [==============================] - 1s 53us/sample - loss: 0.0728 - acc: 0.9786\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.07282146261757007, 0.9786]"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"k9iIBMSAlAfq","colab_type":"text"},"source":["#### Training accuracy"]},{"cell_type":"code","metadata":{"id":"w2RaHnJfkixP","colab_type":"code","outputId":"5cbdb32e-6498-4460-eb74-70743aa580c5","executionInfo":{"status":"ok","timestamp":1559009366485,"user_tz":-540,"elapsed":45781,"user":{"displayName":"김혜주","photoUrl":"","userId":"02435794378876656796"}},"colab":{"base_uri":"https://localhost:8080/","height":53}},"source":["model.evaluate(x_train, y_train)  # train data로도 한번 테스트 해볼까?"],"execution_count":0,"outputs":[{"output_type":"stream","text":["60000/60000 [==============================] - 3s 45us/sample - loss: 0.0236 - acc: 0.9929\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.023638827126581843, 0.99291664]"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"ArzYLkCmlKbg","colab_type":"text"},"source":["이 위 두개의 차이를 아는게 중요한데 test로 나온 정확도를 말해야지. 그런데 test데이터로 97나온걸 어떻게 더 올릴까 생각하기 전에 training데이터를 가지고 어떻게 더 정확도를 올릴지 먼저 고민해야지 봤던 것 자료부터 잘 맞추도록.  안봤던 데이터로 해도 잘나오지만 봤던 데이터로 정확도 나온게 당연히 더 높을 것"]},{"cell_type":"code","metadata":{"id":"9RAcVORCI63s","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}